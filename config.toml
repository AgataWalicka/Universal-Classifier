[data]
scale = 12.5  # Voxel size = 1/scale
val_reps = 1  # Number of test views, 1 or more
batch_size = 6
full_scale = 16384
train_data_path = 'train/*.la[sz]'
validation_data_path = 'val/*.la[sz]'
drop_classes = []  # which classes should be deleted from the training point cloud. E.g., noise
merge_classes = []  # [destinatioin_class, merging_class]  # which classes should be merged. E.g., high, medium, low vegetation into one class
classification_type = 'multiclass' # binary or multiclass

[unet]
use_cuda = true  # optional, default: false - should CUDA be used - the processing is VERY slow when false
cuda_device = 0  # optional, default: 0 - the code can use only one GPU at the time. When more GPUs then one, several models can be trained at once and a specific GPU can be selected for each
restore = false
restore_file_path = ''
m = 16  # number of features generated by each convolutional layer
residual_blocks = true  # should there be residual blocks in the network architecture
block_reps = 1  # number of repetitions of the block
report_save_path = 'results/report.txt'  # a path to the training report. If there is already a file with this name, the logs are appended
training_epochs = 18  # number of training epochs
filter_size = 3  # size of the filter used for convolution operations
class_shares = []  # How often the classes occur
cpk_save_path = ''  # where the trained networks should be saved
figure_save_path = 'Learning process.png' # where the figure should be saved

[unet_test]  # Parameters only for network testing
unet_path = ''  # a path to the trained network
pc_save_path = ''  # where the classified point clouds should be saved